Dear Alicia,

I am writing to you as a concerned citizen of Kambah, Canberra, about the pressing issue of artificial intelligence (AI) and its potential risks to society. As a responsible MP, I believe it is crucial that you are aware of the immediate and long-term risks posed by AI, especially given the current lack of public debate and coordination in this field.

Existing AI systems like Chat-GPT and Midjourney have already demonstrated their potential to spread misinformation or provide access to dangerous information, posing immediate risks to society. However, my primary concern is the emergence of artificial general intelligence (AGI). AGI will be able to process information millions of times faster than humans, it will have access to all the information on the internet. Furthermore, AGI can replicate itself across the internet, making it a formidable force that can pursue its goals, which which may not align with human interests.
 
As you may be aware, several technology companies, including OpenAI, Google Deepmind, and Microsoft, are working towards developing AGI, raising questions about their commitment to AI safety and alignment. Their short-term success is leading to huge investments in AI capabilities without sufficient consideration for alignment with human values. Even their claims of researching "safety" and "alignment" are disputed by AI alignment researchers, highlighting the lack of transparency and accountability in the industry.

These companies are gaining money that they will then use to buy lobbyists and public relations advocates, making decisions whose negative effects will be borne by the public. It is, therefore, crucial that the government takes proactive measures to mitigate these risks, including initiating public debate and awareness campaigns to raise public consciousness on the potential threats posed by AI.

I strongly recommend that you read the article “Pausing AI Developments Isn't Enough. We Need to Shut it All Down” by Eliezer Yudkowsky in Time Magazine. The article proposes slowing down AI development until we have time for public debate and an understanding of the risks, which is a sensible approach given the current state of affairs. OpenAI admits that it doesn't have a foolproof way to align a model that's significantly smarter than we are. Microsoft admits to not understanding what is happening inside GPT-4.

The recklessness of AI research labs, the huge investments in AI, and the lack of regulation are accelerating our progress towards AGI, which is why our government must work quickly on treaties to stop giant AI experiments. Mr Yudkowsky proposes "to stop training large models worldwide until we can confidently achieve alignment of AI’s goals and values with ours." The Campaign for AI Safety and the Future Of Life Institute have also proposed their own solutions to mitigate AI risks.

I urge you to take swift action on this matter to ensure that we harness the benefits of AI while mitigating its potential risks. Thank you for your time and attention.

With kind regards,
Peter Horniak
